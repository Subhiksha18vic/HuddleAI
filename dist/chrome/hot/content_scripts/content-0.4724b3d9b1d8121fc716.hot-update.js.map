{"version":3,"file":"hot/content_scripts/content-0.4724b3d9b1d8121fc716.hot-update.js","mappings":";;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3UA","sources":["webpack://smith/./content/components/SpeechToText.tsx","webpack://smith/webpack/runtime/getFullHash"],"sourcesContent":["__webpack_require__.$Refresh$.runtime = require('/Users/I528960/Documents/Projects/Personal/projectsmith/smith/node_modules/react-refresh/runtime.js');\n\n// import React, { useState, useEffect } from \"react\";\n// const SpeechToText = () => {\n//     const [text, setText] = useState(\"\"); // To store the recognized text\n//     const [isListening, setIsListening] = useState(false);\n//     const [error, setError] = useState(\"\");\n//     let recognition: any;\n//     // Check if SpeechRecognition is available\n//     if (\"webkitSpeechRecognition\" in window || \"SpeechRecognition\" in window) {\n//         const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n//         recognition = new SpeechRecognition();\n//         // SpeechRecognition configuration\n//         recognition.continuous = true; // Keep listening for speech\n//         recognition.interimResults = true; // Only return final results\n//         recognition.lang = \"en-US\"; // Language for recognition\n//     } else {\n//         console.error(\"SpeechRecognition not supported in this browser\");\n//         setError(\"SpeechRecognition not supported in this browser\");\n//     }\n//     // Start listening to speech\n//     const startListening = () => {\n//         if (!recognition) {\n//             return;\n//         }\n//         recognition.start();\n//         setIsListening(true);\n//         // Event listeners\n//         recognition.onresult = (event) => {\n//             let spokenText = \"\";\n//             for (let i = event.resultIndex; i < event.results.length; i++) {\n//                 spokenText += event.results[i][0].transcript;\n//             }\n//             setText((prevText) => prevText + \" \" + spokenText);\n//         };\n//         recognition.onerror = (event) => {\n//             console.error(\"Error occurred in speech recognition: \", event.error);\n//             setError(event.error);\n//             setIsListening(false);\n//         };\n//         recognition.onend = () => {\n//             setIsListening(false);\n//         };\n//     };\n//     // Stop listening to speech\n//     const stopListening = () => {\n//         if (!recognition) {\n//             return;\n//         }\n//         recognition.stop();\n//         setIsListening(false);\n//     };\n//     useEffect(() => {\n//         // Clean up event listeners on component unmount\n//         return () => {\n//             if (recognition) {\n//                 recognition.stop();\n//                 recognition.onresult = null;\n//                 recognition.onerror = null;\n//                 recognition.onend = null;\n//             }\n//         };\n//     }, []);\n//     return (\n//         <div>\n//             <p className=\"mt-6 text-lg leading-8 text-gray-300\">Speech-to-Text Recognition</p>\n//             <div>\n//                 <button\n//                     onClick={startListening}\n//                     disabled={isListening}\n//                     className=\"bg-zinc-100 py-1 px-2 rounded-lg text-zinc-800 text-md hover:bg-zinc-200 hover:shadow-xl focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-white mt-2 font-bold my-4 mr-2\"\n//                 >\n//                     Start Listening\n//                 </button>\n//                 <button\n//                     onClick={stopListening}\n//                     disabled={!isListening}\n//                     className=\"bg-zinc-100 py-1 px-2 rounded-lg text-zinc-800 text-md hover:bg-zinc-200 hover:shadow-xl focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-white mt-2 font-bold my-4 mr-2\"\n//                 >\n//                     Stop Listening\n//                 </button>\n//             </div>\n//             {error && <p style={{ color: \"red\" }}>Error: {error}</p>}\n//             <textarea\n//                 rows={10}\n//                 cols={50}\n//                 value={text}\n//                 onChange={(e) => setText(e.target.value)}\n//                 placeholder=\"Speech will be converted to text here...\"\n//             />\n//         </div>\n//     );\n// };\n// export default SpeechToText;\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {\n    try {\n        var info = gen[key](arg);\n        var value = info.value;\n    } catch (error) {\n        reject(error);\n        return;\n    }\n    if (info.done) {\n        resolve(value);\n    } else {\n        Promise.resolve(value).then(_next, _throw);\n    }\n}\nfunction _async_to_generator(fn) {\n    return function() {\n        var self = this, args = arguments;\n        return new Promise(function(resolve, reject) {\n            var gen = fn.apply(self, args);\n            function _next(value) {\n                asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value);\n            }\n            function _throw(err) {\n                asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err);\n            }\n            _next(undefined);\n        });\n    };\n}\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nvar _s = $RefreshSig$();\nimport React, { useState, useEffect } from \"react\";\nconst TabAudioToText = ()=>{\n    _s();\n    const [text, setText] = useState(\"\"); // To store the recognized text\n    const [isListening, setIsListening] = useState(false);\n    const [error, setError] = useState(\"\");\n    const [stream, setStream] = useState(null);\n    let recognition = null;\n    // Check if SpeechRecognition is available\n    if (\"webkitSpeechRecognition\" in window || \"SpeechRecognition\" in window) {\n        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n        recognition = new SpeechRecognition();\n        // SpeechRecognition configuration\n        recognition.continuous = true; // Keep listening for speech\n        recognition.interimResults = true; // Include interim results\n        recognition.lang = \"en-US\"; // Language for recognition\n    } else {\n        console.error(\"SpeechRecognition not supported in this browser\");\n        setError(\"SpeechRecognition not supported in this browser\");\n    }\n    // Capture tab audio\n    const captureTabAudio = /*#__PURE__*/ function() {\n        var _ref = _async_to_generator(function*() {\n            try {\n                const audioStream = yield navigator.mediaDevices.getDisplayMedia({\n                    video: false,\n                    audio: true\n                });\n                setStream(audioStream);\n                console.log(\"Tab audio captured successfully.\");\n            } catch (err) {\n                console.error(\"Error capturing tab audio:\", err);\n                setError(\"Failed to capture tab audio. Ensure permissions are granted.\");\n            }\n        });\n        return function captureTabAudio() {\n            return _ref.apply(this, arguments);\n        };\n    }();\n    // Start listening to audio from the captured tab\n    const startListening = /*#__PURE__*/ function() {\n        var _ref = _async_to_generator(function*() {\n            if (!recognition) {\n                setError(\"SpeechRecognition is not available.\");\n                return;\n            }\n            if (!stream) {\n                yield captureTabAudio(); // Attempt to capture tab audio if not already captured\n            }\n            if (!stream) {\n                setError(\"Audio stream not available.\");\n                return;\n            }\n            // Start recognition\n            recognition.start();\n            setIsListening(true);\n            // Event listeners for speech recognition\n            recognition.onresult = (event)=>{\n                let spokenText = \"\";\n                for(let i = event.resultIndex; i < event.results.length; i++){\n                    spokenText += event.results[i][0].transcript;\n                }\n                setText((prevText)=>prevText + \" \" + spokenText);\n            };\n            recognition.onerror = (event)=>{\n                console.error(\"Error occurred in speech recognition: \", event.error);\n                setError(event.error);\n                setIsListening(false);\n            };\n            recognition.onend = ()=>{\n                setIsListening(false);\n            };\n        });\n        return function startListening() {\n            return _ref.apply(this, arguments);\n        };\n    }();\n    // Stop listening\n    const stopListening = ()=>{\n        if (!recognition) {\n            return;\n        }\n        recognition.stop();\n        setIsListening(false);\n    };\n    useEffect(()=>{\n        // Cleanup on component unmount\n        return ()=>{\n            if (stream) {\n                stream.getTracks().forEach((track)=>track.stop());\n            }\n            if (recognition) {\n                recognition.stop();\n                recognition.onresult = null;\n                recognition.onerror = null;\n                recognition.onend = null;\n            }\n        };\n    }, [\n        stream\n    ]);\n    return /*#__PURE__*/ _jsxDEV(\"div\", {\n        children: [\n            /*#__PURE__*/ _jsxDEV(\"h1\", {\n                children: \"Browser Tab Audio to Text\"\n            }, void 0, false, {\n                fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                lineNumber: 213,\n                columnNumber: 13\n            }, this),\n            /*#__PURE__*/ _jsxDEV(\"div\", {\n                children: [\n                    /*#__PURE__*/ _jsxDEV(\"button\", {\n                        onClick: startListening,\n                        disabled: isListening,\n                        className: \"bg-blue-500 text-white px-4 py-2 rounded mr-2\",\n                        children: \"Start Listening\"\n                    }, void 0, false, {\n                        fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                        lineNumber: 215,\n                        columnNumber: 17\n                    }, this),\n                    /*#__PURE__*/ _jsxDEV(\"button\", {\n                        onClick: stopListening,\n                        disabled: !isListening,\n                        className: \"bg-red-500 text-white px-4 py-2 rounded\",\n                        children: \"Stop Listening\"\n                    }, void 0, false, {\n                        fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                        lineNumber: 222,\n                        columnNumber: 17\n                    }, this)\n                ]\n            }, void 0, true, {\n                fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                lineNumber: 214,\n                columnNumber: 13\n            }, this),\n            error && /*#__PURE__*/ _jsxDEV(\"p\", {\n                style: {\n                    color: \"red\"\n                },\n                children: [\n                    \"Error: \",\n                    error\n                ]\n            }, void 0, true, {\n                fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                lineNumber: 230,\n                columnNumber: 23\n            }, this),\n            /*#__PURE__*/ _jsxDEV(\"textarea\", {\n                rows: 10,\n                cols: 50,\n                value: text,\n                onChange: (e)=>setText(e.target.value),\n                placeholder: \"Speech will be transcribed here...\",\n                className: \"mt-4 w-full border rounded p-2\"\n            }, void 0, false, {\n                fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n                lineNumber: 231,\n                columnNumber: 13\n            }, this)\n        ]\n    }, void 0, true, {\n        fileName: \"/Users/I528960/Documents/Projects/Personal/projectsmith/smith/content/components/SpeechToText.tsx\",\n        lineNumber: 212,\n        columnNumber: 9\n    }, this);\n};\n_s(TabAudioToText, \"xEmwWLm9wRtnzB0YTC/27FNTAjs=\");\n_c = TabAudioToText;\nexport default TabAudioToText;\nvar _c;\n$RefreshReg$(_c, \"TabAudioToText\");\n\n\nconst $ReactRefreshModuleId$ = __webpack_require__.$Refresh$.moduleId;\nconst $ReactRefreshCurrentExports$ = __react_refresh_utils__.getModuleExports(\n\t$ReactRefreshModuleId$\n);\n\nfunction $ReactRefreshModuleRuntime$(exports) {\n\tif (module.hot) {\n\t\tlet errorOverlay;\n\t\tif (typeof __react_refresh_error_overlay__ !== 'undefined') {\n\t\t\terrorOverlay = __react_refresh_error_overlay__;\n\t\t}\n\t\tlet testMode;\n\t\tif (typeof __react_refresh_test__ !== 'undefined') {\n\t\t\ttestMode = __react_refresh_test__;\n\t\t}\n\t\treturn __react_refresh_utils__.executeRuntime(\n\t\t\texports,\n\t\t\t$ReactRefreshModuleId$,\n\t\t\tmodule.hot,\n\t\t\terrorOverlay,\n\t\t\ttestMode\n\t\t);\n\t}\n}\n\nif (typeof Promise !== 'undefined' && $ReactRefreshCurrentExports$ instanceof Promise) {\n\t$ReactRefreshCurrentExports$.then($ReactRefreshModuleRuntime$);\n} else {\n\t$ReactRefreshModuleRuntime$($ReactRefreshCurrentExports$);\n}","__webpack_require__.h = () => (\"e1d3c3df0b5f18a80a78\")"],"names":[],"sourceRoot":""}